#################
问题描述：给定一系列的实体词，如何利用一段时间的日志来获取实体词的类别；
#################
涉及三个操作：
1. 自动获取种子url；
2. 根据自动获取的种子url，扩展得到更多的url；
3. 依赖url（正负例）、关键词（正负例），获取特征，根据特征来分类；
上述三个操作按正常顺序是1-3依次执行，其中步骤1、2是为了步骤3做准备的，目的是抽取实体词领域的url作为步骤3的分类特征；
因此1、2步骤可以不用执行，人工搜集部分相关的url后直接运行第3个步骤也可以，而且效果可能会更快、更好；
之所以还需要前两个步骤，是为了使整个工具能够自动进行，提高工具的泛华能力，减少人工操作。
下面就详细说明一下我实现这三个步骤所使用的主要策略。
#################
0. 冷启动前准备
自动获取种子url是个冷启动的过程，光靠实体词是无法实现的，因此需要利用实体词和日志统计两个数据：
（1）每条query下每个url的点击频率；
query u1 u1_freq u2 u2_freq u3 u3_freq ...
（2）每个url下每个query的点击频率；
url q1 q1_freq q2 q2_freq q3 q3_freq ...
上面两个看似相同，实则不同。

#################
1. 自动获取种子url
特征：含entity的query点击次数，不含entity的query点击次数，含entity的query点击比例
策略：含实体词的query点击频次（下限：200，上限1000，达到上限的直接取），url总点击频次（下限10，上限200w）
代码：mapreduce获取特征（见auto_seed/auto_m.py、auto_r.py），对特征进行抽取url（见extract_seed.py）
auto_m.py：
输入：实体词文件（每行一条query），日志文件（每行一条日志，格式为"query \t "） 
输出：

auto_r.py：
输入：auto_m.py的输出
输出：每行一条特征："url \t "
样例：
lini816.net114.com  1   0   1.0
jltx.jiam.shgao.com 2   0   1.0
jiuhuiyi.com    2   0   1.0
jclzhlr.net 1   0   1.0
jbkd888.com 1   0   1.0
japannet.taobao.com 1   0   1.0
hssdpf.com  1   0   1.0
hezefuke.com    1   0   1.0
gfkc88.91jm.com 1   0   1.0
gaoencanjitang.dianhi.com   1   0   1.0
flycrm.qianyan.biz  1   0   1.0
fhciba.com  1   0   1.0
emyanwo.com 2   0   1.0
daoxiaomian.dv37.com    1   0   1.0

extract_seed.py
输入：auto_r.py的输出
输出：种子url集合

分析：这里的上限和下限取的有点武断，而
#################
2. 根据自动获取的种子url，扩展得到更多的url
#################
3. 依赖url（正负例）、关键词（正负例），获取特征，根据特征来分类
 
